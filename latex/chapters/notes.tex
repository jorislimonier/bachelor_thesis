\chapter{Notes}

\section{Notes for chapter 1}
To be added
\begin{itemize}
    \item how to get $\hat b$ on page 101.
    \item where the $\chi^2$ distribution comes from in page 101
\end{itemize}

\section{Notes for chapter 2}

\subsection{Linear models}

We consider the setting of having a sample of $n$ observations

\[
    (\X_1, \Y_1), \ldots ,(\X_n, \Y_n)
\]

where $X_i \in \mathscr{X} \subseteq \R^p, \; i = 1, \ldots, n$ and $Y_i \in \mathscr{Y} \subseteq \R, \; i = 1, \ldots, n$. In other words, each of the observations contains $p$ covariates. In the real world this could mean having $n$ patients, $p$ observations per patient and trying to predict an outcome such as having a certain type of cancer.

\begin{definition}[The linear model]
    The relationship between an observation $\X_i \in \mathscr{X}$ and its outcome $\Y_i \in \mathscr{Y}$ can be established by a linear model, that is
    \begin{equation}
        i = 1, \ldots, n \qquad \Y_{i} = \sum_{j=1}^{p} \bta_{j} \X_{i}^{(j)} + \eps_{i}
    \end{equation}
\end{definition}

Instead of seeing each observation individually we can deal with all of them together by expressing the linear model in matrix notation

\begin{equation}
    \label{eqn: linear model (matrix)}
    \Y = \X \bta + \eps
\end{equation}

\begin{definition}
    \begin{enumerate}[label=(\alph*)]
        \item $\X$ is called the \textbf{design matrix}. It has dimension $n \times p$.

              $\X$ consists of stacking the vectors relative to each observation inside of a matrix

              \[
                  X =
                  \begin{bmatrix}
                      \text{---} & X_1^T  & \text{---} \\
                                 & \vdots &            \\
                      \text{---} & X_n^T  & \text{---} \\
                  \end{bmatrix}
              \]
        \item $\bta$ is called the \textbf{parameter vector}. It has dimension $p \times 1$.
        \item $\eps$ is called the \textbf{error vector}. It has dimension $n \times 1$.
        \item $\Y$ is called the \textbf{response vector}. It has dimension $n \times 1$.
    \end{enumerate}
\end{definition}


% Without loss of generality, and after centering and scaling if necessary, we can assume that

% \[
%     \forall j = 1, \ldots, p \quad
%     \begin{cases}
%         \bar{\Y} = \frac{1}{n} \sum \limits_{i=1}^{n} \Y_{i} = 0                                                   \\
%         \sgmhat_{j}^{2} := \frac{1}{n} \sum \limits_{i=1}^{n} \left( \X_{i}^{(j)} - \bar{\X}^{(j)} \right)^{2} = 1 \\
%     \end{cases}
% \]


\subsection{The least squares method}

The least squares problem consists of finding the vector $\btahat$ minimizing the following function
\begin{equation}
    \label{eqn: least squares function}
    S(\bta) = \sum_{i=1}^{n} \varepsilon_{i}^{2} = \eps^{T} \eps = (\Y-\X \bta)^{T}(\Y-\X \bta)
\end{equation}

which may be rewritten as

\begin{align*}
    S(\bta) & = (\Y - \X \bta)^{T} (\Y - \X \bta)                             \\
            & = \Y^T \Y - \Y^T \X \bta - \bta^T \X^T \Y + \bta^T \X^T \X \bta \\
            & = \Y^T \Y - 2 \bta^T \X^T \Y + \bta^T \X^T \X \bta              \\
\end{align*}

We find \( \btahat \) by differentiating \( S \) with respect to $\bta$ and setting this to 0.

\begin{align}
             & \frac{\partial}{\partial \bta} S(\btahat) = 0 \nonumber                                                                  \\
    \implies & \frac{\partial}{\partial \btahat} \left( \Y^T \Y - 2 \btahat^T \X^T \Y + \btahat^T \X^T \X \btahat \right) = 0 \nonumber \\
    \implies & - 2 \X^T \Y + 2 \X^T \X \btahat = 0 \nonumber                                                                            \\
    \implies & \X^T \X \btahat = \X^T \Y \label{eqn: least-squares normal equations}                                                    
\end{align}

where equation \eqref{eqn: least-squares normal equations} is called the least squares normal equations.

If we assume that \( \X^T \X \) is invertible, then \eqref{eqn: least-squares normal equations} yields

\[
    \btahat = (\X^T \X)^{-1} \X^T \Y
\]

\section{Notes for chapter 3}
\subsection{Section 6.2}
We work with an underdetermined system : there are more

We define $\btahat$ as follows
\begin{equation}
    \label{eqn: beta hat (LASSO)}
    \btahat:=\arg \min _{\bta}\left\{ \frac{\|\Y-\X \bta\|_{2}^{2}}{n}+\lambda\|\bta\|_{1} \right\}
\end{equation}

\begin{lemma}[Basic Inequality]
    $$\frac{\| \X (\btahat-\bta^{0})\|_{2}^{2}}{n} + \lambda\|\btahat\|_{1} \leq 2 \frac{\varepsilon^{T} \X (\btahat-\bta^{0})}{n}+\lambda \| \bta^{0} \|_{1}$$
\end{lemma}
\begin{proof}
    By definition of $\btahat$, we have that
    $$
        \forall \bta \quad \frac{\| \Y-\X \btahat \|_{2}^{2}}{n} + \lambda \| \btahat \|_{1} \leq \frac{\|\Y-\X \bta \|_{2}^{2}}{n}+\lambda \| \bta \|_{1}
    $$
    In particular for $\bta = \bta^0$ we have
    $$
        \frac{\| \Y-\X \btahat \|_{2}^{2}}{n}+\lambda\| \btahat \|_{1} \leq \frac{ \| \Y-\X \bta^0\|_{2}^{2}}{n}+\lambda \| \bta^0\|_{1}
    $$
    We now replace $\Y$ using equation \eqref{eqn: linear model (matrix)}.
    \begin{align*}
                 & \frac{\|\Y  - \X \btahat \|_{2}^{2}}{n} + \lambda \| \btahat\|_{1} \leq \frac{\| \Y  - \X \bta^0 \|_2^2}{n}+\lambda\|\bta^{0}\|_{1}                                                     \\
        \implies &
        \frac{\| (\X \bta^0 + \eps) - \X \btahat \|_{2}^{2}}{n}+\lambda\| \btahat \|_{1} \leq \frac{ \| (\X \bta^0 + \eps)-\X \bta^0\|_{2}^{2}}{n}+\lambda \| \bta^0\|_{1}                                 \\
        \implies &
        \frac{\| \X ( \bta^0 - \btahat) + \eps \|_{2}^{2}}{n} + \lambda\| \btahat \|_{1} \leq \frac{ \| \X ( \bta^0 - \bta^0) + \eps \|_{2}^{2}}{n}+\lambda \| \bta^0\|_{1}                                \\
        \implies &
        \frac{\langle \X ( \bta^0 - \btahat) + \eps, \X ( \bta^0 - \btahat) + \eps \rangle}{n}+\lambda \| \btahat \|_{1} \leq \frac{ \| \eps \|_{2}^{2}}{n}+\lambda \| \bta^0\|_{1}                        \\
        \implies &
        \frac{\| \X (\bta^0 - \btahat) \| _2^2 + \| \eps \|_2^2 + 2 \langle \X ( \bta^0 - \btahat),  \eps \rangle}{n}+\lambda \| \btahat \|_{1} \leq \frac{ \| \eps \|_{2}^{2}}{n}+\lambda \| \bta^0\|_{1} \\
        \implies &
        \frac{\| \X (\btahat - \bta^0) \| _2^2}{n} + \lambda \| \btahat \|_{1} \leq \frac{2 \langle \X ( \btahat - \bta^0),  \eps \rangle}{n} + \lambda \| \bta^0\|_{1}                                    \\
        \implies &
        \frac{\| \X (\btahat - \bta^0) \| _2^2}{n} + \lambda \| \btahat \|_{1} \leq \frac{2 \eps^T \X ( \btahat - \bta^0)}{n} + \lambda \| \bta^0\|_{1}                                                    \\
    \end{align*}
\end{proof}


Let
$$\mathscr{T} := \left\{\max _{1 \leq j \leq p} 2 \frac{\left| \varepsilon^{T} \mathbf{X}^{(j)}\right|}{n} \leq \lambda_{0}\right\}$$

\begin{lemma}[Lemma 6.2.]
    For all $t > 0$ and
    $$\lambda_{0}:=2 \sgm \sqrt{\frac{t^{2}+2 \log p}{n}}$$
    we have
    $$\mathbb{P}(\mathscr{T}) \geq 1-2 \exp \left[-t^{2} / 2\right]$$
\end{lemma}
\begin{proof}
    We define

    $$
        V_{j} := \frac{\varepsilon^{T} \mathbf{X}^{(j)}}{\sqrt{n \sgm^{2}}}
    $$

    Then we have
    \begin{align}
        \nonumber
        \mathbb{P}(\mathscr{T})
         & = \P \left( \max _{1 \leq j \leq p} 2 \frac{\left| \varepsilon^{T} \mathbf{X}^{(j)}\right|}{n} \leq 2 \sgm \sqrt{\frac{t^{2}+2 \log p}{n}}  \right) \\
        \nonumber
         & =
        \P \left( \max _{1 \leq j \leq p} \left| \frac{\varepsilon^{T} \mathbf{X}^{(j)}}{\sqrt{n \sgm^{2}}} \right| \leq \sqrt{t^{2}+2 \log p}  \right)        \\
        \nonumber
         & =
        \P \left( \max _{1 \leq j \leq p} | V_{j} | \leq \sqrt{t^{2}+2 \log p}  \right)                                                                        \\
        \nonumber
         & = 1 - \P \left( \max _{1 \leq j \leq p} | V_{j} | > \sqrt{t^{2}+2 \log p}  \right)                                                                  \\
        \nonumber
         & = 1 - \P \left( \bigcup_{j = 1}^{p} | V_{j} | > \sqrt{t^{2}+2 \log p}  \right)                                                                      \\
        \nonumber
         & \geq 1 - \sum_{j = 1}^{p} \P \left( | V_{j} | > \sqrt{t^{2}+2 \log p}  \right)                                                                      \\
        \label{eqn: proof lemma 6.2.}
         & \geq 1 - p \; \P \left( | V_{j} | > \sqrt{t^{2}+2 \log p}  \right)
    \end{align}

    Now, let us define $\zeta := \sqrt{t^{2}+2 \log p}$. \\
    Since $V_j$ is $\mathscr{N} (0,1)$-distributed and $\zeta > 0$.

    \begin{align*}
        \mathbb{P}(V_j > \zeta) & = \frac{1}{\sqrt{2\pi}} \int_\zeta^{\infty} e^{-y^2/2} dy                     \\
                                & < \frac{1}{\sqrt{2\pi}} \int_\zeta^{\infty} \frac{y}{\zeta} * e^{-y^2 / 2} dy \\
                                & = \frac{1}{\zeta \sqrt{2\pi}} \int_\zeta^{\infty} y * e^{-y^2 / 2} dy         \\
                                & = \frac{1}{\zeta\sqrt{2\pi}} e^{-\zeta^2/2}                                   \\
    \end{align*}

    We note that $p \geq 2 \implies \zeta \sqrt{2 \pi} \geq 1$ therefore
    $$
        \mathbb{P}(V_j > \zeta) <  e^{-\zeta^2/2}
    $$
    Moreover by symmetry of the $\mathscr{N} (0,1)$ distribution,

    \begin{align*}
        \mathbb{P} (|V_j| > \zeta) & = \mathbb{P} (V_j > \zeta) + \mathbb{P} (- V_j < - \zeta) \\
                                   & = 2 \mathbb{P} (V_j > \zeta)                              \\
                                   & < 2 e^{-\zeta^2/2}                                        \\
    \end{align*}

    Thus by definition of $\zeta$

    \begin{align*}
        \mathbb{P} (|V_j| > \zeta) & < 2 e^{-\zeta^2/2}                                                             \\
                                   & = 2 \exp \left[ \frac{- \sqrt{t^{2} + 2 \log p} ^2}{2} \right]                 \\
                                   & = 2 \exp \left[ \frac{- t^{2}}{2} - \log p \right]                             \\
                                   & = 2 \exp \left[ \frac{- t^{2}}{2} \right] \exp \left[ \log \frac{1}{p} \right] \\
                                   & = \frac{2}{p} \exp \left[ \frac{- t^{2}}{2} \right]                            \\
    \end{align*}

    Inserting this result into \eqref{eqn: proof lemma 6.2.} we obtain

    \begin{align*}
        \mathbb{P}(\mathscr{T}) & \geq 1 - p \; \P \left( | V_{j} | > \sqrt{t^{2}+2 \log p}  \right) \\
                                & \geq 1 - p \; \frac{2}{p} \exp \left[ \frac{- t^{2}}{2} \right]    \\
                                & = 1 - 2 \exp \left[ \frac{- t^{2}}{2} \right]                      \\
    \end{align*}
\end{proof}

\begin{corollary}[Consistency of the LASSO]
    Assume $\sgm^2 = 1$ for all $j$. We define the regularization parameter as
    $$\lambda = 4 \sgmhat^2 \sqrt{\frac{t^2 + 2 \log p}{n}}$$
    where $\sgmhat$ is some estimator of $\sgm$. \\
    Then with probability at least $1 - \alpha$, where $\alpha := 2 \exp(-t^2/2) + \P (\sgmhat \leq \sgm)$ we have
    $$2 \frac{\| \X (\btahat - \bta^0)\|_2^2}{n} \leq 3 \lambda \| \bta^0 \|_1$$
\end{corollary}

\begin{lemma}[Lemma 6.3.]
    We have on $\mathscr{T}$, with $\lambda \geq 2 \lambda_{0}$,
    \begin{equation}
        \label{eqn: lemma 6.3.}
        2\frac{ \|\mathbf{X} (\btahat-\bta^{0} ) \|_{2}^{2}}{n} + \lambda \|\btahat_{S_{0}^{c}} \|_{1} \leq 3 \lambda \|\btahat_{S_{0}}-\bta_{S_{0}}^{0} \|_{1}
    \end{equation}
\end{lemma}
\begin{proof}
    We start with the Basic Inequality
    $$
        \frac{\| \X (\btahat-\bta^{0})\|_{2}^{2}}{n} + \lambda\|\btahat\|_{1} \leq 2 \frac{\varepsilon^{T} \X (\btahat-\bta^{0})}{n}+\lambda\|\bta^{0}\|_{1}
    $$
    Now since we are on $\mathscr{T}$ and since $2 \lambda_0 \leq \lambda$
    $$
        \frac{\| \X (\btahat-\bta^{0})\|_{2}^{2}}{n} + \lambda\|\btahat\|_{1} \leq \lambda_0 \|\btahat-\bta^{0}\|_1 + \lambda\|\bta^{0}\|_{1}
    $$
    $$
        2 \frac{\| \X (\btahat-\bta^{0})\|_{2}^{2}}{n}+2 \lambda\|\btahat\|_{1} \leq \lambda \|\btahat-\bta^{0} \|_{1}+2 \lambda \|\bta^{0} \|_{1}
    $$
    Let $\bta_{j, S}:=\bta_{j} 1\{j \in S\}$. We use the triangle inequality on the left hand side
    \begin{align*}
        \|\btahat\|_{1}
         & = \|\btahat_{S_{0}} \|_{1} + \|\btahat_{S_{0}^{c}} \|_{1}                                                \\
         & = \|\bta_{S_{0}}^{0} - \bta_{S_{0}}^{0} + \btahat_{S_{0}} \|_{1} + \|\btahat_{S_{0}^{c}} \|_{1}          \\
         & \geq \|\bta_{S_{0}}^{0} \|_{1} - \|\btahat_{S_{0}}-\bta_{S_{0}}^{0} \|_{1}+ \|\btahat_{S_{0}^{c}} \|_{1}
    \end{align*}
    whereas on the right hand side
    \begin{align*}
        \|\btahat-\bta^{0} \|_{1}
         & =  \| (\btahat_{S_{0}} + \btahat_{S_{0}^{c}}) - (\bta_{S_{0}}^{0} + \underbrace{\bta_{S_{0}^{c}}^0)}_{=0} \|_{1} \\
         & =  \| \btahat_{S_{0}}-\bta_{S_{0}}^{0} \|_{1} + \|\btahat_{S_{0}^{c}} \|_{1}
    \end{align*}
    Injecting these two results, we get that
    \begin{align*}
                 & 2 \frac{\| \X (\btahat-\bta^{0})\|_{2}^{2}}{n} + 2 \lambda\|\btahat\|_{1} \leq \lambda \|\btahat-\bta^{0} \|_{1}+2 \lambda \|\bta^{0} \|_{1}                                                                                                \\
        \implies & 2 \frac{\| \X (\btahat-\bta^{0})\|_{2}^{2}}{n} + 2 \lambda \left( \|\bta_{S_{0}}^{0} \|_{1} - \|\btahat_{S_{0}}-\bta_{S_{0}}^{0} \|_{1}+ \|\btahat_{S_{0}^{c}} \|_{1} \right)                                                               \\
                 & \leq \lambda \left( \| \btahat_{S_{0}}-\bta_{S_{0}}^{0} \|_{1} + \|\btahat_{S_{0}^{c}} \|_{1} \right) + 2 \lambda \|\bta^{0} \|_{1}                                                                                                         \\
        \implies & 2 \frac{\| \X (\btahat-\bta^{0})\|_{2}^{2}}{n} + 2 \lambda \|\underbrace{\bta_{S_{0}}^{0}}_{= \bta^0} \|_{1} + \lambda \|\btahat_{S_{0}^{c}} \|_{1} \leq 3 \lambda \| \btahat_{S_{0}}-\bta_{S_{0}}^{0} \|_{1} + 2 \lambda \|\bta^{0} \|_{1} \\
        \implies & 2\frac{ \|\mathbf{X} (\btahat-\bta^{0} ) \|_{2}^{2}}{n} + \lambda \|\btahat_{S_{0}^{c}} \|_{1} \leq 3 \lambda \|\btahat_{S_{0}}-\bta_{S_{0}}^{0} \|_{1}
    \end{align*}
\end{proof}

\begin{definition}[Compatibility condition]
    We say that the compatibility condition is met for the set $S_{0}$, if for some $\phi_{0}>0$, and for all $\bta$ satisfying $ \|\bta_{S_{0}^{c}} \|_{1} \leq 3 \|\bta_{S_{0}} \|_{1}$, it holds that
    \begin{equation}
        \left\| \bta_{S_{0}} \right\|_{1}^{2} \leq \left(\bta^{T} \sgmhat \bta\right) \frac{s_{0}}{\phi_{0}^{2}}
    \end{equation}
\end{definition}

\begin{theorem}[Theorem 6.1.]
    Suppose the compatibility condition holds for $S_{0}$. Then on $\mathscr{T}$, we have for $\lambda \geq 2 \lambda_{0}$,
    $$
        \frac{\|\mathbf{X}(\btahat-\bta^{0})\|_{2}^{2}}{n}+\lambda\|\btahat-\bta^{0}\|_{1} \leq 4 \lambda^{2} \frac{s_{0}}{\phi_{0}^{2}}
    $$
\end{theorem}
\begin{proof}
    Using lemma \ref{eqn: lemma 6.3.} we have that
    \begin{align*}
         & \quad 2 \frac{\|\mathbf{X}(\btahat-\bta^{0})\|_{2}^{2}}{n} + \lambda\|\btahat-\bta^{0}\|_{1}                                                                                                    \\
         & = 2 \frac{\|\mathbf{X}(\btahat-\bta^{0})\|_{2}^{2}}{n} + \lambda \| \btahat_{S_0} + \btahat_{S_{0}^{c}} - \bta^{0}_{S_0} - \underbrace{\bta^{0}_{S_0^c}}_{=0} \|_{1}                            \\
         & = 2 \frac{\|\mathbf{X}(\btahat-\bta^{0})\|_{2}^{2}}{n} + \lambda \| \btahat_{S_0} - \bta^{0}_{S_0} \|_{1} + \lambda \| \btahat_{S_{0}^{c}} \|_1 \quad \textit{(by lemma \ref{eqn: lemma 6.3.})} \\
         & \leq 4 \lambda \|\btahat_{S_{0}} - \bta_{S_{0}}^{0} \|_{1}                                                                                                                                      \\
         & \leq 4 \lambda \sqrt{\left( \btahat_{S_{0}} - \bta_{S_{0}}^{0} \right)^{T} \sgmhat \left( \btahat_{S_{0}} - \bta_{S_{0}}^{0}  \right) s_{0} / \phi_{0}^{2}}                                     \\
         & \leq \sqrt{\left( \btahat_{S_{0}} - \bta_{S_{0}}^{0} \right)^{T} \X^T \X \left( \btahat_{S_{0}} - \bta_{S_{0}}^{0}  \right)} \frac{4 \lambda \sqrt{s_{0}}}{\phi_{0} \sqrt{n}}                   \\
         & \leq \| \X ( \btahat_{S_{0}} - \bta_{S_{0}}^{0} ) \|_2 \frac{4 \lambda \sqrt{s_{0}}}{\phi_{0} \sqrt{n}}                                                                                         \\
         & \leq \| \X ( \btahat_{S_{0}} - \bta_{S_{0}}^{0} ) \|^2_2 + \frac{4 \lambda^2 s_{0}}{\phi^2_{0} n}                                                                                               \\
    \end{align*}
    Where the last inequality follows from $4uv \leq u^2 + 4v^2$.
\end{proof}


\subsection{Section 6.3}

Now $\mathbf{Y} :=\mathbf{f}^{0} + \eps$, therefore $\mathbb{E} [\mathbf{Y}] :=\mathbf{f}^{0}$.


\begin{lemma}[New version of the Basic Inequality]
    $\forall \bta^* \in \R^p$ we have
    \begin{equation}
        \frac{\|\X \btahat - \mathbf{f}^0 \|_{2}^{2}}{n} + \lambda\| \btahat \|_{1} \leq \frac{2 \eps^T \X (\btahat - \bta^*)}{n} + \lambda \| \bta^*\|_{1} + \frac{\|\X \bta^* - \mathbf{f}^0\|_{2}^{2}}{n}
    \end{equation}
\end{lemma}
\begin{proof}
    By definition of $\btahat$, we have that
    $$
        \forall \bta \quad \frac{\| \Y -\X \btahat \|_{2}^{2}}{n} + \lambda \| \btahat \|_{1} \leq \frac{\|\Y-\X \bta \|_{2}^{2}}{n}+\lambda \| \bta \|_{1}
    $$
    In particular for $\bta = \bta^*$ we have
    $$
        \forall \bta^* \quad \frac{\| \Y -\X \btahat \|_{2}^{2}}{n} + \lambda \| \btahat \|_{1} \leq \frac{\|\Y-\X \bta^* \|_{2}^{2}}{n}+\lambda \| \bta \|_{1}
    $$
    We since $\Y = \mathbf{f}^0 + \eps$
    \begin{align*}
                 & \frac{\|\Y  - \X \btahat \|_{2}^{2}}{n} + \lambda \| \btahat\|_{1} \leq \frac{\| \Y  - \X \bta^* \|_2^2}{n}+\lambda\|\bta^{0}\|_{1}                                                                     \\
        \implies &
        \frac{\| (\mathbf{f}^0 + \eps) - \X \btahat \|_{2}^{2}}{n} + \lambda\| \btahat \|_{1} \leq \frac{ \| (\mathbf{f}^0 + \eps)-\X \bta^*\|_{2}^{2}}{n}+\lambda \| \bta^*\|_{1}                                         \\
        \implies &
        \frac{\| (\mathbf{f}^0 - \X \btahat ) + \eps \|_{2}^{2}}{n} + \lambda\| \btahat \|_{1} \leq \frac{ \| (\mathbf{f}^0 - \X \bta^*) + \eps \|_{2}^{2}}{n}+\lambda \| \bta^*\|_{1}                                     \\
        \implies &
        \frac{\langle (\mathbf{f}^0 - \X \btahat ) + \eps, (\mathbf{f}^0 - \X \btahat ) + \eps \rangle}{n} + \lambda\| \btahat \|_{1}                                                                                      \\
                 & \leq \frac{ \langle (\mathbf{f}^0 - \X \bta^*) + \eps, (\mathbf{f}^0 - \X \bta^*) + \eps \rangle}{n}+\lambda \| \bta^*\|_{1}                                                                            \\
        \implies &
        \frac{\|\mathbf{f}^0 - \X \btahat \|_{2}^{2} + \| \eps \|_{2}^{2} + 2\langle \mathbf{f}^0 - \X \btahat, \eps \rangle}{n} + \lambda\| \btahat \|_{1}                                                                \\
                 & \leq \frac{\|\mathbf{f}^0 - \X \bta^* \|_{2}^{2} + \| \eps \|_{2}^{2} + 2\langle \mathbf{f}^0 - \X \bta^*, \eps \rangle}{n}+\lambda \| \bta^*\|_{1}                                                     \\
        \implies &
        \frac{\|\X \btahat - \mathbf{f}^0 \|_{2}^{2}}{n} + \lambda\| \btahat \|_{1} \leq \frac{2\langle \X (\btahat - \bta^*), \eps \rangle}{n} + \lambda \| \bta^*\|_{1} + \frac{\|\X \bta^* - \mathbf{f}^0\|_{2}^{2}}{n} \\
        \implies &
        \frac{\|\X \btahat - \mathbf{f}^0 \|_{2}^{2}}{n} + \lambda\| \btahat \|_{1} \leq \frac{2 \eps^T \X (\btahat - \bta^*)}{n} + \lambda \| \bta^*\|_{1} + \frac{\|\X \bta^* - \mathbf{f}^0\|_{2}^{2}}{n}               \\
    \end{align*}
\end{proof}

\begin{lemma}[New version of Lemma 6.3.]
    We have on $\mathscr{T}$, with $\lambda \geq 4 \lambda_{0}$,
    \begin{equation}
        \label{eqn: new version of lemma 6.3.}
        \frac{4 \|\mathbf{X} \btahat-\mathbf{f}^0\|_{2}^{2}}{n} + 3 \lambda \| \btahat_{S^{c}_{*}} \|_{1} \leq 5 \lambda \| \btahat_{S_{*}} - \bta_{S_{*}}^{*} \|_{1} + \frac{4 \|\mathbf{X} \bta^{*} - \mathbf{f}^{0} \|_{2}^{2}}{n}
    \end{equation}
    where $S_* := \{ j: \bta_j^* \neq 0 \}$.
\end{lemma}
\begin{proof}
    We start with the Basic Inequality
    $$
        \frac{\|\X \btahat - \mathbf{f}^0 \|_{2}^{2}}{n} + \lambda\| \btahat \|_{1} \leq  \frac{2 \eps^T \X (\btahat - \bta^*)}{n} + \lambda \| \bta^*\|_{1} + \frac{\|\X \bta^* - \mathbf{f}^0\|_{2}^{2}}{n}
    $$
    Now since we are on $\mathscr{T}$ and since $4 \lambda_0 \leq \lambda$
    \begin{align*}
                 & \frac{\|\X \btahat - \mathbf{f}^0 \|_{2}^{2}}{n} + \lambda\| \btahat \|_{1} \leq  \frac{2 \eps^T \X (\btahat - \bta^*)}{n} + \lambda \| \bta^*\|_{1} + \frac{\|\X \bta^* - \mathbf{f}^0\|_{2}^{2}}{n} \\
        \implies &
        \frac{\|\X \btahat - \mathbf{f}^0 \|_{2}^{2}}{n} + \lambda\| \btahat \|_{1} \leq \lambda_0 \| \btahat - \bta^* \|_{1} + \lambda \| \bta^*\|_{1} + \frac{\|\X \bta^* - \mathbf{f}^0\|_{2}^{2}}{n}                 \\
        \implies &
        4 \frac{\| \X \btahat - \mathbf{f}^0 \|_{2}^{2}}{n} + 4 \lambda\| \btahat \|_{1} \leq \lambda \| \btahat - \bta^* \|_{1} + 4 \lambda \| \bta^*\|_{1} + 4\frac{\|\X \bta^* - \mathbf{f}^0\|_{2}^{2}}{n}           \\
    \end{align*}
    We use the triangle inequality on the left hand side
    \begin{align*}
        \|\btahat\|_{1}
         & = \|\btahat_{S_{*}} \|_{1} + \|\btahat_{S_{*}^{c}} \|_{1}                                                \\
         & = \|\bta_{S_{*}}^{*} - \bta_{S_{*}}^{*} + \btahat_{S_{*}} \|_{1} + \|\btahat_{S_{*}^{c}} \|_{1}          \\
         & \geq \|\bta_{S_{*}}^{*} \|_{1} - \|\btahat_{S_{*}}-\bta_{S_{*}}^{*} \|_{1}+ \|\btahat_{S_{*}^{c}} \|_{1}
    \end{align*}
    whereas on the right hand side
    \begin{align*}
        \|\btahat-\bta^{*} \|_{1}
         & =  \| (\btahat_{S_{*}} + \btahat_{S_{*}^{c}}) - (\bta_{S_{*}}^{*} + \underbrace{\bta_{S_{*}^{c}}^*}_{=0}) \|_{1} \\
         & =  \| \btahat_{S_{*}}-\bta_{S_{*}}^{*} \|_{1} + \|\btahat_{S_{*}^{c}} \|_{1}
    \end{align*}
    Injecting these two results, we get that
    \begin{align*}
                 & 4 \frac{\| \X \btahat - \mathbf{f}^0 \|_{2}^{2}}{n} + 4 \lambda\| \btahat \|_{1} \leq \lambda \| \btahat - \bta^* \|_{1} + 4 \lambda \| \bta^*\|_{1} + 4\frac{\|\X \bta^* - \mathbf{f}^0\|_{2}^{2}}{n} \\
        \implies &
        4 \frac{\| \X \btahat - \mathbf{f}^0 \|_{2}^{2}}{n} + 4 \lambda \left( \|\bta_{S_{*}}^{*} \|_{1} - \|\btahat_{S_{*}}-\bta_{S_{*}}^{*} \|_{1}+ \|\btahat_{S_{*}^{c}} \|_{1} \right)                                \\
                 & \leq \lambda \left( \| \btahat_{S_{*}}-\bta_{S_{*}}^{*} \|_{1} + \|\btahat_{S_{*}^{c}} \|_{1} \right) + 4 \lambda \| \bta^*\|_{1} + 4\frac{\|\X \bta^* - \mathbf{f}^0\|_{2}^{2}}{n}                    \\
        \implies &
        4 \frac{\| \X \btahat - \mathbf{f}^0 \|_{2}^{2}}{n} + 4 \lambda \| \underbrace{\bta_{S_{*}}^{*}}_{= \bta^{*}} \|_{1} + 3 \lambda\|\btahat_{S_{*}^{c}} \|_{1}                                                      \\
                 & \leq 5 \lambda \| \btahat_{S_{*}}-\bta_{S_{*}}^{*} \|_{1} + 4 \lambda \| \bta^*\|_{1} + 4\frac{\|\X \bta^* - \mathbf{f}^0\|_{2}^{2}}{n}                                                                \\
        \implies &
        4 \frac{\| \X \btahat - \mathbf{f}^0 \|_{2}^{2}}{n} + 3 \lambda\|\btahat_{S_{*}^{c}} \|_{1} \leq 5 \lambda \| \btahat_{S_{*}}-\bta_{S_{*}}^{*} \|_{1} + 4\frac{\|\X \bta^* - \mathbf{f}^0\|_{2}^{2}}{n}           \\
    \end{align*}
\end{proof}

% Compare  equation \eqref{eqn: lemma 6.3.} and equation \eqref{eqn: new version of lemma 6.3.}. We have that 

\begin{definition}[Compatibility condition for general sets]
    We say that the compatibility condition holds for the set $S$, if for some constant $\phi(S)>0,$ and for all $\bta,$ with $\left\|\bta_{S^{c}}\right\|_{1} \leq$ $3\left\|\bta_{S}\right\|_{1},$ one has
    $$
        \left\|\bta_{S}\right\|_{1}^{2} \leq\left(\bta^{T} \sgmhat \bta\right)\frac{|S|}{\phi^{2}(S)}
    $$
\end{definition}

We define $\mathscr{S}$ as the collection of sets $S$ for which the compatibility condition holds.

\begin{definition}[The oracle]
    We define the oracle $\bta^{*}$ as
    $$
        \bta^{*} = \arg \min_{\bta: S_{\bta} \in \mathscr{S}} \left\{ \frac{ \left\| \X \bta - \f^{0} \right\|_{2}^{2}}{n} + \frac{4 \lambda^{2} s_{\bta}}{\phi^{2}\left(S_{\bta}\right)}\right\}
    $$
    where $S_{\bta}:=\left\{j: \bta_{j} \neq 0\right\}$, $s_{\bta}:=\left|S_{\bta}\right|$ denotes the cardinality of $S_{\bta}$ and the factor 4 in the right hand side comes from choosing $\lambda \geq \lambda_0$.
\end{definition}




